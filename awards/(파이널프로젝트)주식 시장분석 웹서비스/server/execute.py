import streamlit as st
import pandas as pd
from datetime import datetime,timedelta
import bs4
import requests
from pykrx import stock
import matplotlib.pyplot as plt
import numpy as np
from pymongo import MongoClient
import re
from PIL import Image
from datetime import date, timedelta


from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression # ÏïôÏÉÅÎ∏î Ï°∞Ìï©Ïö©
from sklearn.neighbors import KNeighborsClassifier # ÏïôÏÉÅÎ∏î Ï°∞Ìï©Ïö©
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
import xgboost as xgb

from sklearn.preprocessing import *
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM, GRU
from sklearn.metrics import mean_squared_error, r2_score
import tensorflow as tf

#@st.cache(suppress_st_warning=True)

class SideTab():
    def __init__(self):
        #self.data1 = pd.read_csv('/Users/junho/Desktop/stream/data/data_not_scaled.csv')
        #self.data2 = pd.read_csv('/Users/junho/Desktop/stream/data/·Ñè·Ö°·Ñè·Ö°·Ñã·Ö© ·Ñê·ÖÆ·Ñå·Ö°·Ñå·Ö°·Ñá·Öß·ÜØ ·ÑÜ·Ö¢·ÑÜ·Ö¢·ÑÉ·Ö©·Üº·Ñí·Ö£·Üº.csv', encoding='cp949')
        
        pass
    '''
    def sidebar_price_widget(self):
        data = self.data1.iloc[-2:,[5,6,2]]
        with st.sidebar:
            for col in range(len(data.columns)):
                st.metric(label=f'{data.columns[col]}', value=f'{data.iloc[1,col]} P',
                          delta=f'{round(data.iloc[1,col]-data.iloc[0,col],2)} '
                                f'({round(round(data.iloc[1,col]-data.iloc[0,col],2)/round(data.iloc[0,col],2)*100,2)}%)',
                          delta_color='off')

    def sidebar_volume_widget(self):
        data = self.data2
        data = pd.DataFrame(data.iloc[0,[1,3,4]])
        data = data.transpose()

        with st.sidebar:
            for col in range(len(data.columns)):
                st.metric(label=f'{data.columns[col]}', value=f'{data.iloc[0,col]}',
                          delta_color='off')
    '''
    def sidebar_price_now(self,comp,comp_code):
        my_client = MongoClient('mongodb://18.181.49.139:27017')
        mydb = my_client['final_project']
        tp = pd.DataFrame(mydb['company_price'].find({})).drop('_id',axis=1)
        tp.set_index('code',inplace=True)
        rate = round(tp.loc[comp_code,'Îì±ÎùΩÎ•†'],2)
        yesterday_price = tp.loc[comp_code,'Ï†ÑÏùºÎπÑ']
        with st.sidebar:
            st.metric(label=comp,
                      value=f"{tp.loc[comp_code,'Ï¢ÖÍ∞Ä']} Ïõê",
                          delta=f'{yesterday_price}({rate}%)',
                          delta_color='off')
        '''
        url = f'https://finance.naver.com/item/main.naver?code={comp_code}'
        headers = {
            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36'}

        res = requests.get(url, headers=headers)
        bs_obj = bs4.BeautifulSoup(res.text)
        today = bs_obj.find_all('p', {'class': 'no_today'})
        exday = bs_obj.find_all('p', {'class': 'no_exday'})
        temp0 = [i.text for i in today][0].split('\n')
        temp = [i.text for i in exday][0].split('\n')

        tp = -int(temp[5].replace(',',''))

        if 'ÌïòÎùΩ' in temp:
            with st.sidebar:
                st.metric(label=comp,
                          value=f"{temp0[2]} Ïõê",
                          delta=f'{tp} (-{temp[-4]}%)',
                          delta_color='off')
        elif 'ÏÉÅÏäπ' in temp:
            with st.sidebar:
                st.metric(label=comp,
                    value=f"{temp0[2]} Ïõê",
                    delta=f'{temp[5]} ({temp[-4]}%)',
                    delta_color='off')
        '''
    def sidebar_price_widget(self,comp,comp_code):
        my_client = MongoClient('mongodb://18.181.49.139:27017')
        mydb = my_client['final_project']
        tp = pd.DataFrame(mydb['side_price'].find({})).drop('_id',axis=1)
        tp.set_index('code',inplace=True)
        rate = round(tp.loc[comp_code,'Îì±ÎùΩÎ•†'],2)
        yesterday_price = round(tp.loc[comp_code,'Ï†ÑÏùºÎπÑ'],2)
        with st.sidebar:
            st.metric(label=comp,
                      value=f"{tp.loc[comp_code,'Ï¢ÖÍ∞Ä']}",
                          delta=f'{yesterday_price}({rate}%)',
                          delta_color='off')
        '''
        url = 'http://www.krx.co.kr/main/main.jsp'
        headers = {
            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36'}

        res = requests.get(url, headers=headers)
        bs_obj = bs4.BeautifulSoup(res.text)
        data = bs_obj.find_all('div', {'class': 'section-wap-top'})

        temp = [i.text for i in data][0].split('\n')
        columns = []
        ls = []

        for i in range(len(temp)):
            if not temp[i]:
                continue
            else:
                if temp[i][0] == 'K':
                    columns.append(temp[i])
                else:
                    ls.append(temp[i].split())

        for i in ls:
            if "‚ñº" in i[0]:
                i[0] = i[0].replace('‚ñº', '')
                i[1] = -float(i[1])
                i[2] = i[2].strip('(').strip(')')
            else:
                i[0] = i[0].replace('‚ñ≤', '')
                i[2] = i[2].strip('(').strip(')')

        columns = [columns[1], columns[3]]
        ls = [ls[1], ls[3]]

        with st.sidebar:
            for col in range(len(columns)):
                st.metric(label=f'{columns[col]}',
                          value=f'{ls[col][0]} P',
                          delta=f'{ls[col][1]} ({ls[col][2]}%)',
                          delta_color='off')

        '''
class Article():
    def __init__(self,company):
        if company == 'Ïπ¥Ïπ¥Ïò§':
            company = 'kakao'
        else:
            company = 'naver'
        my_client = MongoClient('mongodb://18.181.49.139:27017')
        mydb = my_client['final_project']
        self.data = pd.DataFrame(mydb[f'{company}_article'].find({}))
        
        '''
        date_list = []
        title_list = []
        info_list = []
        url_list = []

        if company == 'Ïπ¥Ïπ¥Ïò§':
            code = '035720' # kakao
        else:
            code = '035420' # naver
        page = 1

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36 Edg/101.0.1210.32'}

        url = f'https://finance.naver.com/item/news_news.naver?code={code}&page={page}&sm=title_entity_id.basic&clusterId='
        res = requests.get(url, headers=headers)
        bs = bs4.BeautifulSoup(res.text, 'html.parser')

        while datetime.strftime(datetime.now().date() + timedelta(days=-day), '%Y-%m-%d') not in date_list:
            url = f'https://finance.naver.com/item/news_news.naver?code={code}&page={page}&sm=title_entity_id.basic&clusterId='
            res = requests.get(url, headers=headers)
            bs = bs4.BeautifulSoup(res.text, 'html.parser')

            date_list.extend([i.text.split()[0].replace('.', '-') for i in bs.find_all('td', {'class': 'date'})])
            title_list.extend([i.text.replace('\n', '') for i in bs.find_all('td', {'class': 'title'})])
            info_list.extend([i.text for i in bs.find_all('td', {'class': 'info'})])
            url_list.extend(
                ['https://finance.naver.com' + i.find('a')['href'] for i in bs.find_all('td', {'class': 'title'})])

            page += 1

        self.data = pd.DataFrame([date_list, title_list, info_list, url_list], index=['ÎÇ†Ïßú', 'Ï†úÎ™©', 'Ï†ïÎ≥¥Ï†úÍ≥µ', 'ÎßÅÌÅ¨']).transpose()
        self.data = self.data.drop_duplicates('Ï†úÎ™©')
        '''

    def company_list(self):
        return list(self.data.value_counts('Ï†ïÎ≥¥Ï†úÍ≥µ').reset_index()['Ï†ïÎ≥¥Ï†úÍ≥µ'])  # 17

    def recent_article(self,head):
        companys = list(pd.DataFrame(self.data.value_counts('Ï†ïÎ≥¥Ï†úÍ≥µ')).reset_index()['Ï†ïÎ≥¥Ï†úÍ≥µ'])
        stream_show = []
        for company in companys:
            stream_show.append(self.data.groupby('Ï†ïÎ≥¥Ï†úÍ≥µ').get_group(company).head(head))
        return stream_show

    def recent_article_mark(self,data,head=30):
        #recent = self.recent_article(head)
        recent = data
        article_setting = []
        for compnum in range(len(recent)):
            temp = []
            for dnum in ['ÎÇ†Ïßú', 'Ï†úÎ™©', 'ÎßÅÌÅ¨']:
                temp.append(list(recent[compnum].loc[:, ['ÎÇ†Ïßú', 'Ï†úÎ™©', 'ÎßÅÌÅ¨']][dnum]))
            article_setting.append(temp)
        return article_setting

    def company_article(self):
        head = 10

        col1, col2 = st.columns(2)

        art = self.recent_article_mark(self.recent_article(head), head)
        cl = self.company_list()
        cnt = 0
        for company in range(len(cl)):
            if cnt == 0:
                with col1:
                    st.markdown(f'# üëâ {cl[company]}')
                    for i in range(head):
                        try:
                            st.markdown(f'({art[company][0][i]}) [{art[company][1][i]}]({art[company][2][i]})')
                        except:
                            break
                cnt += 1
            else:
                with col2:
                    st.markdown(f'# üëâ {cl[company]}')
                    for i in range(head):
                        try:
                            st.markdown(f'({art[company][0][i]}) [{art[company][1][i]}]({art[company][2][i]})')
                        except:
                            break
                cnt = 0

    def range_article(self):
        #t1 = datetime.now()

        #data['time label'] = [(t1 - datetime.strptime(data.loc[i, 'ÎÇ†Ïßú'], '%Y-%m-%d')).days >= days for i in
        #                      range(len(data))]
        #data = data[data['time label'] == False]
        data = self.data.loc[:, ['ÎÇ†Ïßú', 'Ï†úÎ™©', 'ÎßÅÌÅ¨']]

        cnt = 0
        for idx in range(30):
            try:
                if idx <= 30:
                    st.markdown(f'({data.iloc[idx,0]}) [{data.iloc[idx,1].replace("[","").replace("]","")}]({data.iloc[idx,2]})')
            except:
                break

        expanders = st.expander("See explanation")
        for idx in range(30,len(data)):
            expanders.markdown(f'({data.iloc[idx,0]}) [{data.iloc[idx,1]}]({data.iloc[idx,2]})')

    def range_article_data(self,days):
        data = self.data
        t1 = datetime.now()

        data['time label'] = [(t1 - datetime.strptime(data.loc[i, 'ÎÇ†Ïßú'], '%Y-%m-%d')).days >= days for i in
                              range(len(data))]
        data = data[data['time label'] == False]
        data = data.loc[:, ['ÎÇ†Ïßú', 'Ï†úÎ™©', 'ÎßÅÌÅ¨']]
        return data
class Company():
    # Í∏∞ÏóÖ Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Îäî Ìï®Ïàò
    def __init__(self):
        pass

    def get_company_info(self, code):  # Ï¢ÖÎ™©ÏΩîÎìúÏôÄ ÌöåÏÇ¨Î™ÖÏùÑ Ïù∏ÏûêÎ°ú Î∞õÏùå
        url = f'https://finance.naver.com/item/main.naver?code={code}'

        # header Ï†ïÎ≥¥ Î∞õÍ≥† ÌååÏã±
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'}
        res = requests.get(url, headers=headers)
        bs = bs4.BeautifulSoup(res.text, 'html.parser')

        table = bs.find('div', {'id': 'tab_con1'})

        total = table.find('em', {'id': '_market_sum'}).text.strip().replace('\t', '').replace('\n', '') + 'ÏñµÏõê'
        rank = table.find_all('em')[1].text + 'ÏúÑ'
        stock = table.find_all('em')[2].text
        foreign = table.find_all('em')[5].text
        foreign_num = table.find_all('em')[6].text
        foreign_rate = table.find_all('em')[7].text
        opinion = table.find('span', {'class': 'f_up'}).text
        goal = table.find_all('em')[9].text
        high52 = table.find_all('em')[10].text
        low = table.find_all('em')[11].text
        # PER - Ï∂îÍ∞ÄÏÇ¨Ìï≠
        per = table.find_all('em')[12].text + 'Î∞∞'
        # EPS - Ï∂îÍ∞ÄÏÇ¨Ìï≠
        eps = table.find_all('em')[13].text + 'Ïõê'

        # Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏúºÎ°ú ÏûëÏÑ±
        # df = pd.DataFrame([total, rank, stock, foreign, foreign_num, foreign_rate, opinion, goal, high52, low],
        #               index = ['ÏãúÍ∞ÄÏ¥ùÏï°','ÏãúÍ∞ÄÏ¥ùÏï°ÏàúÏúÑ','ÏÉÅÏû•Ï£ºÏãùÏàò','Ïô∏Íµ≠Ïù∏ÌïúÎèÑÏ£ºÏãùÏàò','Ïô∏Íµ≠Ïù∏Î≥¥Ïú†Ï£ºÏãùÏàò','Ïô∏Íµ≠Ïù∏ÏÜåÏßÑÏú®','Ìà¨ÏûêÏùòÍ≤¨','Î™©ÌëúÏ£ºÍ∞Ä','52Ï£ºÏµúÍ≥†','ÏµúÏ†Ä'])
        # df.columns = [f'{company}']

        return total, rank, stock, foreign, foreign_num, foreign_rate, opinion, goal, high52, low, per, eps
        # return df

    def get_company_info_df(self, comp, total, rank, stock, foreign, foreign_num, foreign_rate, goal, high52, low, per,
                            eps):
        comp_df1 = pd.DataFrame({
            'ÏãúÍ∞ÄÏ¥ùÏï°': [f'{total:^20}'],
            'ÏãúÍ∞ÄÏ¥ùÏï°ÏàúÏúÑ': [f'{rank:^20}'],
            'ÏÉÅÏû•Ï£ºÏãùÏàò': [f'{stock:^20}']}, index=[f'{comp}'])
        comp_df2 = pd.DataFrame({
            'Ïô∏Íµ≠Ïù∏ÌïúÎèÑÏ£ºÏãùÏàò(A)': [f'{foreign:^20}'],
            'Ïô∏Íµ≠Ïù∏Î≥¥Ïú†Ï£ºÏãùÏàò(B)': [f'{foreign_num:^20}'],
            'Ïô∏Íµ≠Ïù∏ÏÜåÏßÑÏú®(B/A)': [f'{foreign_rate:^20}']}, index=[f'{comp}'])
        comp_df3 = pd.DataFrame({
            'Î™©ÌëúÏ£ºÍ∞Ä': [f'{goal:^20}'],
            '52Ï£ºÏµúÍ≥†': [f'{high52:^20}'],
            'ÏµúÏ†Ä': [f'{low:^20}']}, index=[f'{comp}'])
        comp_df4 = pd.DataFrame({
            'PER': [f'{per:^30}'],
            'EPS': [f'{eps:^30}']}, index=[f'{comp}'])

        return comp_df1.style.set_properties(**{'background-color': '#898EA2',
                                                'color': 'white',
                                                'border-color': '#35455C',
                                                'text-align': 'center'}), comp_df2.style.set_properties(
            **{'background-color': '#898EA2',
               'color': 'white',
               'border-color': '#35455C',
               'text-align': 'center'}), comp_df3.style.set_properties(**{'background-color': '#898EA2',
                                                                          'color': 'white',
                                                                          'border-color': '#35455C',
                                                                          'text-align': 'center'}), comp_df4.style.set_properties(
            **{'background-color': '#898EA2',
               'color': 'white',
               'border-color': '#35455C',
               'text-align': 'center'})
                                                                          
    def get_company_class(self, code='035720'):
        url = f'https://comp.kisline.com/hi/HI0100M010GE.nice?stockcd={code}&nav=1'
        
        headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'}
        res = requests.get(url, headers = headers)
        bs = bs4.BeautifulSoup(res.text, 'html.parser')
        
        # ÌöåÏÇ¨Îì±Í∏â Ï†ïÎ≥¥ ÌÖåÏù¥Î∏î
        table = bs.find('div', {'class': 'grade'})
        class_tab = table.findAll('article')
        opinion = table.find('ul') 
        opinion = opinion.findAll('li')

        # ÌöåÏÇ¨Ï±ÑÎì±Í∏â
        bond_rate = class_tab[0].text.strip()

        # Í∏∞ÏóÖÏñ¥ÏùåÎì±Í∏â commercial paper
        cp = class_tab[1].text.strip()

        # ÌòÑÍ∏àÌùêÎ¶ÑÎì±Í∏â cash flow
        cf = class_tab[2].text.strip()

        # AI Îì±Í∏â
        ai = class_tab[3].text.strip()
        
        # Îì±Í∏â ÏùòÍ≤¨
        bond_op = opinion[0].text.split('Îì±Í∏âÏ†ïÏùò')[1]
        cp_op = opinion[1].text.split('Îì±Í∏âÏ†ïÏùò')[1]
        cf_op = opinion[2].text.split('Îì±Í∏âÏ†ïÏùò')[1]
        ai_op = opinion[3].text.split('Îì±Í∏âÏ†ïÏùò')[1]

        c_list = [bond_rate, cp, cf, ai]
        class_list = ['ÌöåÏÇ¨Ï±ÑÎì±Í∏â', 'Í∏∞ÏóÖÏñ¥ÏùåÎì±Í∏â', 'ÌòÑÍ∏àÌùêÎ¶ÑÎì±Í∏â', 'AIÎì±Í∏â']
        class_info = [] # Í∏∞ÏóÖÎì±Í∏â 
        date = [] # Ïû¨Î¨¥Í∏∞Ï§ÄÏùº
        date2 = [] # ÌèâÍ∞ÄÏùº
        organ = [] # ÌèâÍ∞ÄÍ∏∞Í¥Ä

        for info, class_name in zip(c_list, class_list): # Îì±Í∏â Ï†ïÎ≥¥ Îã¥Í∏∞
            try:
                class_info.append(info.split(f'{class_name}')[1].split('Ïû¨')[0])
            except:
                class_info.append('-')
        for info in c_list: # Ïû¨Î¨¥Í∏∞Ï§ÄÏùº Îã¥Í∏∞
            try:
                date.append(info.split('Ïû¨Î¨¥Í∏∞Ï§ÄÏùº')[1].split('Ìèâ')[0])
            except:
                date.append('-')
        for info in c_list: # ÌèâÍ∞ÄÏùº Îã¥Í∏∞
            try:
                date2.append(info.split('ÌèâÍ∞ÄÏùº')[1].split('Ìèâ')[0])
            except:
                date2.append('-')
        for info in c_list: # ÌèâÍ∞ÄÍ∏∞Í¥Ä Îã¥Í∏∞
            try:
                organ.append(info.split('ÌèâÍ∞ÄÍ∏∞Í¥Ä')[1].split()[0])
            except:
                organ.append('-')

        class_df = pd.DataFrame(columns = ['Îì±Í∏â', 'Ïû¨Î¨¥Í∏∞Ï§ÄÏùº','ÌèâÍ∞ÄÏùº','ÌèâÍ∞ÄÍ∏∞Í¥Ä', 'ÏÉÅÏÑ∏ÏÑ§Î™Ö'], index = class_list)
        class_df['Îì±Í∏â'] = class_info
        class_df['Ïû¨Î¨¥Í∏∞Ï§ÄÏùº'] = date
        class_df['ÌèâÍ∞ÄÏùº'] = date2
        class_df['ÌèâÍ∞ÄÍ∏∞Í¥Ä'] = organ
        class_df['ÏÉÅÏÑ∏ÏÑ§Î™Ö'] = [bond_op, cp_op, cf_op, ai_op]
        
        return class_df.style.set_properties(**{'background-color': '#898EA2',
                                                'color': 'white',
                                                'border-color': '#35455C',
                                                'text-align': 'center'})
        
    def get_company_summary(self, code = '035720'):
        url = f'https://comp.kisline.com/hi/HI0100M010GE.nice?stockcd={code}&nav=1'
        headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'}
        res = requests.get(url, headers = headers)
        bs = bs4.BeautifulSoup(res.text, 'html.parser')
        table = bs.find_all('section',{'class':'con'})
        title = table[6].find('thead',{'class':'aln_l'})
        summ_title = title.find_all('th')[0].text # Í∞úÏöî Ï†úÎ™©
        pres_title = title.find_all('th')[1].text # ÌòÑÌô© Ï†úÎ™©
        
        content = table[6].find('tbody')
        summ_content = content.find_all('td')[0].text.strip().split('.')[:-1]
        pres_content = content.find_all('td')[1].text.strip().split('.')[:-1]
        
        # Îç∞Ïù¥ÌÑ∞ ÌîÑÎ†àÏûÑ ÎßåÎì§Í∏∞
        summ_df = pd.DataFrame()
        summ_df[f'{summ_title}'] = summ_content
        summ_df[f'{pres_title}'] = pres_content
        
        return summ_title, pres_title, summ_content, pres_content
    
    
    def get_consensus(self, code = '035720'):
        url = f'https://comp.kisline.com/cn/CN0100M010GE.nice?stockcd={code}&nav=5'
        headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'}
        res = requests.get(url, headers = headers)
        bs = bs4.BeautifulSoup(res.text, 'html.parser')
        table = bs.find_all('div',{'class','tbl'})[11]
        table = table.find('tbody', {'class':'aln_r'})
        lines = table.find_all('tr')

        info = []
        for i in range(0, len(lines)):
            text = re.sub(r'\(\s[0-9]\.0\)', '', lines[i].text.strip())
            info.append(text.split(' '))
            
        op_df = pd.DataFrame(columns = ['Í∏∞Í¥ÄÎ™Ö','Ï∂îÏ†ïÏùºÏûê','Ï†ÅÏ†ïÏ£ºÍ∞Ä','ÏßÅÏ†ÑÏ†ÅÏ†ïÏ£ºÍ∞Ä','Ï¶ùÍ∞êÎ•†','Ìà¨ÏûêÏùòÍ≤¨','ÏßÅÏ†ÑÌà¨ÏûêÏùòÍ≤¨'])

        for idx in range(0, len(info)):
            op_df.loc[idx] = info[idx]
        op_df = op_df.set_index('Í∏∞Í¥ÄÎ™Ö')
        
        return op_df.style.set_properties(**{'background-color': '#898EA2',
                                                'color': 'white',
                                                'border-color': '#35455C',
                                                'text-align': 'center'})
class Prediction():
    def __init__(self,company): # input : classifier,features
        my_client = MongoClient('mongodb://18.181.49.139:27017')
        self.mydb = my_client['final_project']
        self.basic_numeric = pd.DataFrame(self.mydb[f'{company}_all'].find()).drop(['_id'],axis=1)
        self.numeric = self.basic_numeric.loc[:len(self.basic_numeric),['vix','ÏΩîÏä§Ìîº','ÏΩîÏä§Îã•','Í∞úÏù∏Îß§ÏàòÎüâ',
                                                                         'Í∏∞Í¥ÄÌï©Í≥ÑÎß§ÏàòÎüâ','Ïô∏Íµ≠Ïù∏Ìï©Í≥ÑÎß§ÏàòÎüâ','score1', 'score2','score3','Îì±ÎùΩÎ•†']]
        self.numeric = self.numeric.astype('float64')

        self.pred_target =self.basic_numeric.iloc[-1,:]
        # df Î™®Ïñë
        label_list = list(self.numeric['Îì±ÎùΩÎ•†'])
        tp = []

        for i in label_list:
            if i > 0:
                tp.append(1)
            else:
                tp.append(0)
        self.label = pd.DataFrame(tp)
        self.company = company
        
    # bundle(dtc(),)
    def bundle(self, classifier, features, test_size):

        total_tbl_train = self.numeric.loc[:, features]
        total_tbl_label = self.label.iloc[:, 0]

        X_train, X_test, y_train, y_test = train_test_split(total_tbl_train
                                                            ,total_tbl_label
                                                            ,test_size=test_size,
                                                            random_state=10)

        #DecisionTree = DecisionTreeClassifier(random_state=10)
        #Logistic = LogisticRegression(random_state=10)
        #KNeighbors = KNeighborsClassifier(n_neighbors=4)
        #Voting = VotingClassifier(estimators=[('LR', Logistic), ('KN', KNeighbors)], voting='hard')
        #RandomForest = RandomForestClassifier(random_state=10)
        #GradientBoosting = GradientBoostingClassifier(random_state=10)
        #XGB = xgb.XGBClassifier(random_state=10)
        #choice = {'DecisionTree': self.dtc(), 'Logistic': Logistic, 'KNeighbors': KNeighbors,
        #          'Voting': Voting, 'RandomForest': RandomForest, 'GradientBoosting': GradientBoosting,
        #          'XGB': XGB}

        clf = classifier
        clf.fit(X_train, y_train)  # classifier
        acc_pred = clf.predict(X_test)
        acc = np.round(accuracy_score(y_test, acc_pred), 4)

        pred = clf.predict(np.array(self.pred_target[features]).reshape(1,-1))
        if int(pred) == 1:
            st.success(f'Îç∞Ïù¥ÌÑ∞Îäî {datetime.strftime((datetime.now()).date()-timedelta(days=1), "%Y-%m-%d")} ÍπåÏßÄÏùò Îç∞Ïù¥ÌÑ∞ ÏûÖÎãàÎã§. Ïò§Îäò {self.company} Ï£ºÍ∞ÄÎäî ÏÉÅÏäπÌï†Í≤ÉÏúºÎ°ú ÏòàÏ∏°Îê©ÎãàÎã§. ÏòàÏ∏° Ï†ïÌôïÎèÑÎäî {round(acc * 100, 2)}% ÏûÖÎãàÎã§.')
        elif int(pred) == 0:
            st.success(f'Îç∞Ïù¥ÌÑ∞Îäî {datetime.strftime((datetime.now()).date()-timedelta(days=1), "%Y-%m-%d")} ÍπåÏßÄÏùò Îç∞Ïù¥ÌÑ∞ ÏûÖÎãàÎã§. Ïò§Îäò {self.company} Ï£ºÍ∞ÄÎäî ÌïòÎùΩÌï†Í≤ÉÏúºÎ°ú ÏòàÏ∏°Îê©ÎãàÎã§. ÏòàÏ∏° Ï†ïÌôïÎèÑÎäî {round(acc * 100, 2)}% ÏûÖÎãàÎã§.')
        
        return round(acc * 100, 2),pred

    def dtc(self,max_depth,min_samples_leaf,min_samples_split):

        return DecisionTreeClassifier(random_state=10,
                                      max_depth=max_depth,
                                      min_samples_leaf=min_samples_leaf,
                                      min_samples_split=min_samples_split)

    def logi(self,l1_ratio):
        return LogisticRegression(random_state=10,penalty='elasticnet',l1_ratio=l1_ratio,solver='saga')

    def kNN(self,n_neighbors):
        return KNeighborsClassifier(n_neighbors=n_neighbors)

    def Vote(self):
        return VotingClassifier(estimators=[('LR', self.logi(0.5)), ('KN', self.kNN(4))])

    def RanF(self,max_depth,min_samples_leaf,min_samples_split,max_samples):
        return RandomForestClassifier(random_state=10,
                                      max_depth=max_depth,
                                      min_samples_leaf=min_samples_leaf,
                                      min_samples_split=min_samples_split,
                                      bootstrap=True,
                                      max_samples=max_samples)

    def GradB(self,max_depth,min_samples_leaf,min_samples_split,learning_rate):
        return GradientBoostingClassifier(random_state=10,
                                          max_depth=max_depth,
                                          min_samples_leaf=min_samples_leaf,
                                          min_samples_split=min_samples_split,
                                          learning_rate=learning_rate)

    def xgB(self):
        return xgb.XGBClassifier(random_state=10)
    
class visualization():

    def __init__(self):
        pass

    def volume(self,code):
        # Îß§Îß§ÎèôÌñ• Îç∞Ïù¥ÌÑ∞
        try:
            pykrx_df = stock.get_market_trading_volume_by_investor(
                fromdate=datetime.strftime(
                    (datetime.now()-timedelta(days=1)).date(), '%Y-%m-%d'),
                todate=datetime.strftime(
                    (datetime.now()).date(), '%Y-%m-%d'),
                ticker=code)
        except:
            pykrx_df = stock.get_market_trading_volume_by_investor(
                fromdate=datetime.strftime(
                    (datetime.now() - timedelta(days=2)).date(), '%Y-%m-%d'),
                todate=datetime.strftime(
                    (datetime.now() - timedelta(days=1)).date(), '%Y-%m-%d'),
                ticker=code)

        pykrx_df = pykrx_df.loc[['Í∏∞Í¥ÄÌï©Í≥Ñ','Í∞úÏù∏','Ïô∏Íµ≠Ïù∏'],'ÏàúÎß§Ïàò']
        # Í∏∞ÌÉÄÎ≤ïÏù∏,Í∏∞ÌÉÄÏô∏Íµ≠Ïù∏ Ï†úÏô∏
        x = pykrx_df.index
        fig, ax = plt.subplots(facecolor="#9aa6bc")
        ax = plt.bar(x,pykrx_df)
        plt.ylabel('volume')
        st.pyplot(fig)

    def mean_price(self,code):
        try:
            pykrx_df = stock.get_market_ohlcv_by_date(
                fromdate=datetime.strftime(
                    (datetime.now()-timedelta(days=365)).date(), '%Y-%m-%d'),
                todate=datetime.strftime(
                    (datetime.now()).date(), '%Y-%m-%d'),
                ticker=code,
                adjusted=False)
        except:
            pykrx_df = stock.get_market_ohlcv_by_date(
                fromdate=datetime.strftime(
                    (datetime.now() - timedelta(days=366)).date(), '%Y-%m-%d'),
                todate=datetime.strftime(
                    (datetime.now() - timedelta(days=1)).date(), '%Y-%m-%d'),
                ticker=code,
                adjusted=False)

        x = pykrx_df.index
        fig, ax = plt.subplots(facecolor="#9aa6bc")
        plt.plot(x, pykrx_df['Ï¢ÖÍ∞Ä'], color='#5d81df')
        plt.plot(x, pykrx_df['Ï¢ÖÍ∞Ä'].rolling(window=20).mean(), color='#fdaaf8')
        plt.plot(x, pykrx_df['Ï¢ÖÍ∞Ä'].rolling(window=60).mean(), color='#58e4da')  # acc9b7 Ïó∞Îëê
        plt.plot(x, pykrx_df['Ï¢ÖÍ∞Ä'].rolling(window=120).mean(), color='#feff0f')



        plt.grid()
        plt.xlabel('day')
        plt.ylabel('price')
        plt.legend(['Close','20days','60days','120days'])

        st.pyplot(fig)

    def price(self,code):
        try:
            pykrx_df = stock.get_market_ohlcv_by_date(
                fromdate=datetime.strftime(
                    (datetime.now()-timedelta(days=365)).date(), '%Y-%m-%d'),
                todate=datetime.strftime(
                    (datetime.now()).date(), '%Y-%m-%d'),
                ticker=code,
                adjusted=False)
        except:
            pykrx_df = stock.get_market_ohlcv_by_date(
                fromdate=datetime.strftime(
                    (datetime.now() - timedelta(days=366)).date(), '%Y-%m-%d'),
                todate=datetime.strftime(
                    (datetime.now() - timedelta(days=1)).date(), '%Y-%m-%d'),
                ticker=code,
                adjusted=False)

        x = pykrx_df.index
        fig, ax = plt.subplots(facecolor="#9aa6bc")
        ax = plt.plot(x, pykrx_df['Ï¢ÖÍ∞Ä'])

        plt.grid()
        plt.xlabel('day')
        plt.ylabel('price')

        st.pyplot(fig)
class deeplearning():
    def __init__(self):
        my_client = MongoClient('mongodb://18.181.49.139:27017')
        self.mydb = my_client['final_project']

    def get_data(self, comp):
        data = pd.DataFrame(self.mydb[f'{comp}_all'].find()).drop('_id',axis=1)
        data.set_index("ÎÇ†Ïßú",inplace=True)
        data_idx = data.index
        return data, data_idx

    def min_max(self, data, features, labels):
        feature_scaler = MinMaxScaler()
        label_scaler = MinMaxScaler()
        ms_feaures = feature_scaler.fit_transform(data[features])
        ms_label = label_scaler.fit_transform(data[labels].values.reshape(-1,1))
        df_ms_feaures = pd.DataFrame(ms_feaures, columns=features)
        df_ms_labels = pd.DataFrame(ms_label, columns=labels)

        return df_ms_feaures, df_ms_labels, label_scaler

    def make_dataset(self, data, label, window_size=20):
        feature_list = []
        label_list = []
        for i in range(len(data) - window_size):
            feature_list.append(np.array(data.iloc[i:i+window_size]))
            label_list.append(np.array(label.iloc[i+window_size]))
        return np.array(feature_list), np.array(label_list)

    def lstm_model(self,data,idx,feature,label,train,epoch,batch,sequence,act,opt):
        tf.random.set_seed(56)
        data_feature, data_label, label_scaler = self.min_max(data,feature,label)
        train_feature, train_label= self.make_dataset(data_feature[:train],data_label[:train],sequence)
        test_feature, test_label = self.make_dataset(data_feature[train:],data_label[train:],sequence)
        x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2,random_state=56)
        model = Sequential()
        model.add(LSTM(32,
                    input_shape=(train_feature.shape[1], train_feature.shape[2]),
                    activation=act,
                    return_sequences=False)
                )
        model.add(Dense(1))
        model.compile(loss='mean_squared_error', optimizer=opt, metrics=["mean_squared_error"])
        history = model.fit(x_train, y_train, 
                            epochs=epoch, 
                            batch_size=batch,
                            validation_data=(x_valid, y_valid))

        pred_test = model.predict(test_feature)

        # rescaled
        # Ïã§Ï†úÍ∞í
        rescaled_actual = data[label].iloc[-len(test_label):]
        # ÏòàÏ∏°Í∞í
        rescaled_pred = label_scaler.inverse_transform(np.array(pred_test).reshape(-1,1))
        idx = list(idx)
        df = pd.DataFrame(rescaled_pred,columns=["Ï¢ÖÍ∞Ä"])
        df.index = idx[train+sequence:]
        # ÎÇ¥ÏùºÏòàÏ∏°Í∞í
        data_tm = []
        data_tm.append(np.array(data_feature.iloc[-sequence:]))
        data_tm = np.array(data_tm)
        pred_price = model.predict(data_tm)
        rescaled_pred_price = label_scaler.inverse_transform(np.array(pred_price).reshape(-1,1))
        predict_price = rescaled_pred_price[0][0]
        
        c_rate = predict_price/df["Ï¢ÖÍ∞Ä"].iloc[-1]
        c_price = rescaled_actual.iloc[-1] * c_rate
        rate = (c_rate * 100) - 100
        return rescaled_actual, df, int(round(c_price,-2)), np.round(rate,2)

    def gru_model(self,data,idx,feature,label,train,epoch,batch,sequence,act,opt):
        tf.random.set_seed(56)
        data_feature, data_label, label_scaler = self.min_max(data,feature,label)
        train_feature, train_label= self.make_dataset(data_feature[:train],data_label[:train],sequence)
        test_feature, test_label = self.make_dataset(data_feature[train:],data_label[train:],sequence)
        x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2,random_state=56)
        model = Sequential()
        model.add(GRU(32,
                    input_shape=(train_feature.shape[1], train_feature.shape[2]),
                    activation=act,
                    return_sequences=False)
                )
        model.add(Dense(1))
        model.compile(loss='mean_squared_error', optimizer=opt, metrics=["mean_squared_error"])
        history = model.fit(x_train, y_train, 
                            epochs=epoch, 
                            batch_size=batch,
                            validation_data=(x_valid, y_valid))

        pred_test = model.predict(test_feature)

        # rescaled
        # Ïã§Ï†úÍ∞í
        rescaled_actual = data[label].iloc[-len(test_label):]
        # ÏòàÏ∏°Í∞í
        rescaled_pred = label_scaler.inverse_transform(np.array(pred_test).reshape(-1,1))
        idx = list(idx)
        df = pd.DataFrame(rescaled_pred,columns=["Ï¢ÖÍ∞Ä"])
        df.index = idx[train+sequence:]
        # ÎÇ¥ÏùºÏòàÏ∏°Í∞í
        data_tm = []
        data_tm.append(np.array(data_feature.iloc[-sequence:]))
        data_tm = np.array(data_tm)
        pred_price = model.predict(data_tm)
        rescaled_pred_price = label_scaler.inverse_transform(np.array(pred_price).reshape(-1,1))
        predict_price = rescaled_pred_price[0][0]
        
        c_rate = predict_price/df["Ï¢ÖÍ∞Ä"].iloc[-1]
        c_price = rescaled_actual.iloc[-1] * c_rate
        rate = (c_rate * 100) - 100
        return rescaled_actual, df, int(round(c_price,-2)), np.round(rate,2)

    def make_graph(self, act, pred):
        fig, ax = plt.subplots(facecolor="#9aa6bc")
        ax = plt.plot(act, label='Ïã§Ï†ú Ï£ºÍ∞Ä')
        ax = plt.plot(pred, label='ÏòàÏ∏° Ï£ºÍ∞Ä')
        plt.rc('font',family = 'Malgun Gothic')
        plt.xlabel(xlabel="ÎÇ†Ïßú",size = 8)
        plt.ylabel(ylabel="Í∞ÄÍ≤©",size = 8)
        plt.xticks(range(0,len(act),int(len(act)/10)), rotation = 30, size = 7)
        plt.yticks(size=6)
        plt.legend()
        st.pyplot(fig)

    def do_predict(self,act,pred):
        rmse = np.sqrt(mean_squared_error(act,pred))
        r2 = r2_score(act,pred)
        return np.round(rmse,2), np.round(r2,2)
class feargreed():
    def __init__(self, comp):
        my_client = MongoClient('mongodb://18.181.49.139:27017')
        mydb = my_client['final_project']
        if comp == 'Ïπ¥Ïπ¥Ïò§':
            df = pd.DataFrame(mydb['kakao_feargreed'].find({})).drop('_id',axis=1)
        else:
            df = pd.DataFrame(mydb['naver_feargreed'].find({})).drop('_id',axis=1)
            
        df['ÎÇ†Ïßú'] = pd.to_datetime(df['ÎÇ†Ïßú'])
        
        df = df.sort_values(by='ÎÇ†Ïßú', ascending=False).reset_index(drop=True)
        
        df['Í≥µÌè¨ÌÉêÏöï'] = df['BERT'] + df['LSTM']
        df['Í≥µÌè¨ÌÉêÏöï'] = df['Í≥µÌè¨ÌÉêÏöï'] - df['Í≥µÌè¨ÌÉêÏöï'].mean()
        self.df = df
        self.df_fg = (df[['ÎÇ†Ïßú','Í≥µÌè¨ÌÉêÏöï']].groupby('ÎÇ†Ïßú').mean().rolling(7).mean()*100).dropna()
        self.df_lb = (df[['ÎÇ†Ïßú','LSTM','BERT']].groupby('ÎÇ†Ïßú').mean().rolling(7).mean()*100-50).dropna() 
        
    def load_img(self,day):
        x = self.df_fg['Í≥µÌè¨ÌÉêÏöï'][day.isoformat()]
        if x >= 5:
            chk = 4
        elif 5 > x >= 0:
            chk = 3
        elif 0 > x >= -3:
            chk = 2
        else:
            chk = 1
        return Image.open(f'data/feargreed_{chk}.png')

    def get_comments(self,day):
        df = self.df
        greed_comments = df[df['ÎÇ†Ïßú'] == day.isoformat()].sort_values(by='Í≥µÌè¨ÌÉêÏöï')['ÎåìÍ∏Ä'].head(7).to_list()
        fear_comments = df[df['ÎÇ†Ïßú'] == day.isoformat()].sort_values(by='Í≥µÌè¨ÌÉêÏöï')['ÎåìÍ∏Ä'].tail(7).to_list()
        return fear_comments, greed_comments
    
    def get_period_df(self,period_check):
        period_dict = {'1Ï£º':2, '2Ï£º':3, '1Í∞úÏõî':5, '3Í∞úÏõî':13, '6Í∞úÏõî':25, '1ÎÖÑ':52}
        day = (date.today() - timedelta(weeks=period_dict[period_check])).isoformat()
        df2, df3 = self.df_fg, self.df_lb
        df2, df3 = df2[df2.index >= day], df3[df3.index >= day]
        return df2, df3
    
    def get_fg_score(self,day):
        def chk_fg(x):
            if x >= 5:
                return 'Îß§Ïö∞ ÌÉêÏöï'
            elif 5 > x >= 0:
                return 'ÌÉêÏöï'
            elif 0 > x >= -3:
                return 'Í≥µÌè¨'
            else:
                return 'Îß§Ïö∞ Í≥µÌè¨'
        df2 = self.df_fg    
        x = df2[df2.index >= (date.today()-timedelta(days=day)).isoformat()]['Í≥µÌè¨ÌÉêÏöï'].mean()
        return chk_fg(x), f': {round(x,2)}Ï†ê'

#my_client = MongoClient('mongodb://localhost:27017')
#mydb = my_client['final_project']
#pd.DataFrame(mydb['kakao_score'].find())
